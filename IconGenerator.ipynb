{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "from IPython.display import HTML, clear_output\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from util import load_data, random_samples, plot, interpolation, animation\n",
    "\n",
    "from gan import GAN\n",
    "from wgangp import WGANGP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "\n",
    "Data loading is currently implemented in two ways:\n",
    "\n",
    "- Load all pngs in a directory\n",
    "- Load a hdf5 file\n",
    "\n",
    "The `load_data` function returns the data and the resulting shape. In the case of loading a hdf5 file, the resulting shape may be different than the requested shape. In the case of loading pngs, it is attempting to convert the images to the requested color mode and then filters out images that do not fit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode: 1 - grayscale\n",
    "#       2 - grayscale with alpha\n",
    "#       3 - rgb\n",
    "#       4 - rgb with alpha\n",
    "mode = 3\n",
    "desired_shape = (32, 32, mode)  # width x height x color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, desired_shape = load_data('LLD-icon-sharp.hdf5') # from https://data.vision.ee.ethz.ch/sagea/lld/\n",
    "#imgs, desired_shape = load_data('scrapper/faviconpngs2/', desired_shape)\n",
    "\n",
    "# The shape of the loaded data can be different than the requested shape in the case of hdf5\n",
    "print(desired_shape)\n",
    "mode = desired_shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Shows samples of the loaded data\n",
    "random_samples(imgs, mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiating the GAN\n",
    "\n",
    "There are currently two included GAN types, the original GAN and the improved Wasserstein GAN (WGANGP).\n",
    "\n",
    "The GANs can be loaded with different network architectures from `libs/architectures`. They define which layers are included in the generator and discriminator. Current architectures:\n",
    "\n",
    "- dense (for grayscale)\n",
    "- conv1 (inspired by the ACGAN)\n",
    "- conv2 (improved for good results)\n",
    "- resnet (using [WGANGP ResNet32](https://github.com/igul222/improved_wgan_training/blob/master/gan_cifar_resnet.py) as reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#gan = GAN(desired_shape, architecture='dense')\n",
    "#gan = GAN(desired_shape, architecture='conv1')\n",
    "gan = GAN(desired_shape, architecture='conv2')\n",
    "#gan = WGANGP(desired_shape, architecture='resnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d_loss, d_acc, g_loss = gan.train(X_train=imgs, epochs=30000, batch_size=32, sample_interval=200)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(\"images/\" + \"29800.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3,1)\n",
    "axs[0].plot(d_loss)\n",
    "axs[1].plot(d_acc)\n",
    "axs[2].plot(g_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, c = 4, 6\n",
    "noise = np.random.normal(0, 1, (r * c+1, 100))\n",
    "\n",
    "gen_imgs = gan.generator.predict(noise)\n",
    "gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "plot(gen_imgs, mode, r, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r,c,steps = 4,6,32\n",
    "interpol = interpolation(gan,r*c,steps)\n",
    "anim = animation(interpol,mode,r,c,steps)\n",
    "HTML(anim.to_jshtml())\n",
    "\n",
    "## For saving the animation:\n",
    "#anim.save('line.gif', dpi=80, writer='imagemagick')\n",
    "# with reflection:\n",
    "#animation(interpol + interpol[::-1], mode,r,c,steps*2).save('line.gif', dpi=80, writer='imagemagick')\n",
    "# if it's not looping, use 'convert line.gif -loop 0 anim.gif' (using imagemagick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animation(interpol + interpol[::-1], mode,r,c,steps*2).save('anim.gif', dpi=80, writer='pillow')\n",
    "gan.generator_model.save_weights('weights_g.h5')\n",
    "gan.critic_model.save_weights('weights_d.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
